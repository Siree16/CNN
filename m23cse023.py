# -*- coding: utf-8 -*-
"""M23CSE023.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1M21lrupOPfxqlyGmplHrkGfnnmI-aEzL
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets
from torchvision.transforms import ToTensor
from torch.utils.data import DataLoader
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

train_data = datasets.MNIST(
    root='data',
    train=True,
    transform=ToTensor(),
    download=True
)

test_data = datasets.MNIST(
    root='data',
    train=False,
    transform=ToTensor(),
    download=True
)

loaders = {
    'train': DataLoader(train_data,
                        batch_size=20,
                        shuffle=True,
                        num_workers=1),
    'test': DataLoader(test_data,
                       batch_size=20,
                       shuffle=True,
                       num_workers=1)
}

class CNN(nn.Module):
    def __init__(self, num_classes=10):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 16, kernel_size=7, padding=3)
        self.maxpool1 = nn.MaxPool2d(2, stride=1)
        self.conv2 = nn.Conv2d(16, 8, kernel_size=5, padding=2)
        self.maxpool2 = nn.MaxPool2d(2, stride=1)
        self.conv3 = nn.Conv2d(8, 4, kernel_size=3, padding=1)
        self.avgpool = nn.AvgPool2d(2, stride=2)
        self.fc_out = nn.Linear(self.calculate_fc_size(), num_classes)

    def calculate_fc_size(self):
        x = torch.randn(1, 1, 28, 28)
        x = self.maxpool1(self.conv1(x))
        x = self.maxpool2(self.conv2(x))
        x = self.avgpool(self.conv3(x))
        return x.view(-1).size(0)

    def forward(self, x):
        x = F.relu(self.maxpool1(self.conv1(x)))
        x = F.relu(self.maxpool2(self.conv2(x)))
        x = F.relu(self.avgpool(self.conv3(x)))
        x = x.view(-1, self.calculate_fc_size())
        x = self.fc_out(x)

        return F.softmax(x, dim=1)

num_classes = 10
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

model = CNN(num_classes).to(device)
optimizer = optim.Adam(model.parameters(), lr=0.001)
loss_fn = nn.CrossEntropyLoss()

def train(epoch):
    model.train()
    for batch_idx, (data, target) in enumerate(loaders['train']):
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = loss_fn(output, target)
        loss.backward()
        optimizer.step()
        if batch_idx % 20 == 0:
            print(f'Train Epoch:{epoch} [{batch_idx * len(data)}/{len(loaders["train"].dataset)} ({100. * batch_idx/len(loaders["train"]):.0f}%)] \t{loss.item():.6f}')

def test():
    model.eval()
    test_loss = 0
    correct = 0

    with torch.no_grad():
        for data, target in loaders['test']:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += loss_fn(output, target).item()
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()

    test_loss /= len(loaders['test'].dataset)
    accuracy = correct / len(loaders['test'].dataset)
    print(f'\nTest Set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loaders["test"].dataset)} ({100. * accuracy:.0f}%)\n')

    return accuracy

train_loss_values = []
train_accuracy_values = []
test_loss_values = []
test_accuracy_values = []

for epoch in range(1, 11):
    train(epoch)
    test()


    model.train()
    train_loss = 0
    correct_train = 0
    total_train = 0

    for batch_idx, (data, target) in enumerate(loaders['train']):
        data, target = data.to(device), target.to(device)
        output = model(data)
        loss = loss_fn(output, target)
        train_loss += loss.item()
        _, predicted = output.max(1)
        total_train += target.size(0)
        correct_train += predicted.eq(target).sum().item()

    train_loss_values.append(train_loss / len(loaders['train']))
    train_accuracy_values.append(correct_train / total_train)

    model.eval()
    test_loss = 0
    correct_test = 0
    total_test = 0

    with torch.no_grad():
        for data, target in loaders['test']:
            data, target = data.to(device), target.to(device)
            output = model(data)
            loss = loss_fn(output, target)
            test_loss += loss.item()
            _, predicted = output.max(1)
            total_test += target.size(0)
            correct_test += predicted.eq(target).sum().item()

    test_loss_values.append(test_loss / len(loaders['test']))
    test_accuracy_values.append(correct_test / total_test)



epochs = range(1, 11)
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(epochs, train_accuracy_values, label='Training Accuracy')
plt.plot(epochs, test_accuracy_values, label='Testing Accuracy')
plt.title('Accuracy per Epoch')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(epochs, train_loss_values, label='Training Loss')
plt.plot(epochs, test_loss_values, label='Testing Loss')
plt.title('Loss per Epoch')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()


model.eval()
all_predictions = []
all_targets = []

with torch.no_grad():
    for data, target in loaders['test']:
        data, target = data.to(device), target.to(device)
        output = model(data)
        _, predicted = output.max(1)
        all_predictions.extend(predicted.cpu().numpy())
        all_targets.extend(target.cpu().numpy())


cm = confusion_matrix(all_targets, all_predictions)


classes = [str(i) for i in range(10)]  # Classes are digits 0-9
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)
disp.plot(cmap='viridis', values_format='d')
plt.title('Confusion Matrix for the Test Set')
plt.show()





import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets
from torchvision.transforms import ToTensor
from torch.utils.data import DataLoader
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

train_data = datasets.MNIST(
    root='data',
    train=True,
    transform=ToTensor(),
    download=True
)

test_data = datasets.MNIST(
    root='data',
    train=False,
    transform=ToTensor(),
    download=True
)

def combine_classes(target):
    if target == 0 or target == 6:
        return 0
    elif target == 1 or target == 7:
        return 1
    elif target == 2 or target == 3 or target == 8 or target == 5:
        return 2
    elif target == 4 or target == 9:
        return 3

train_data.targets = torch.tensor([combine_classes(target) for target in train_data.targets])
test_data.targets = torch.tensor([combine_classes(target) for target in test_data.targets])

loaders = {
    'train': DataLoader(train_data, batch_size=20, shuffle=True, num_workers=1),
    'test': DataLoader(test_data, batch_size=20, shuffle=True, num_workers=1)
}

class CNN(nn.Module):
    def __init__(self, num_classes=4):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 16, kernel_size=7, padding=3)
        self.maxpool1 = nn.MaxPool2d(2, stride=1)
        self.conv2 = nn.Conv2d(16, 8, kernel_size=5, padding=2)
        self.maxpool2 = nn.MaxPool2d(2, stride=1)
        self.conv3 = nn.Conv2d(8, 4, kernel_size=3, padding=1)
        self.avgpool = nn.AvgPool2d(2, stride=2)
        self.fc_out = nn.Linear(self.calculate_fc_size(), num_classes)

    def calculate_fc_size(self):
        x = torch.randn(1, 1, 28, 28)
        x = self.maxpool1(self.conv1(x))
        x = self.maxpool2(self.conv2(x))
        x = self.avgpool(self.conv3(x))
        return x.view(-1).size(0)

    def forward(self, x):
        x = F.relu(self.maxpool1(self.conv1(x)))
        x = F.relu(self.maxpool2(self.conv2(x)))
        x = F.relu(self.avgpool(self.conv3(x)))
        x = x.view(-1, self.calculate_fc_size())
        x = self.fc_out(x)
        return F.softmax(x, dim=1)

num_classes = 4
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

model = CNN(num_classes).to(device)
optimizer = optim.Adam(model.parameters(), lr=0.001)
loss_fn = nn.CrossEntropyLoss()

def train(epoch):
    model.train()
    for batch_idx, (data, target) in enumerate(loaders['train']):
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = loss_fn(output, target)
        loss.backward()
        optimizer.step()
        if batch_idx % 20 == 0:
            print(f'Train Epoch:{epoch} [{batch_idx * len(data)}/{len(loaders["train"].dataset)} ({100. * batch_idx/len(loaders["train"]):.0f}%)] \t{loss.item():.6f}')

def test():
    model.eval()
    test_loss = 0
    correct = 0

    with torch.no_grad():
        for data, target in loaders['test']:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += loss_fn(output, target).item()
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()

    test_loss /= len(loaders['test'].dataset)
    accuracy = correct / len(loaders['test'].dataset)
    print(f'\nTest Set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loaders["test"].dataset)} ({100. * accuracy:.0f}%)\n')

    return accuracy

train_loss_values = []
train_accuracy_values = []
test_loss_values = []
test_accuracy_values = []

for epoch in range(1, 11):
    train(epoch)
    test()


    model.train()
    train_loss = 0
    correct_train = 0
    total_train = 0

    for batch_idx, (data, target) in enumerate(loaders['train']):
        data, target = data.to(device), target.to(device)
        output = model(data)
        loss = loss_fn(output, target)
        train_loss += loss.item()
        _, predicted = output.max(1)
        total_train += target.size(0)
        correct_train += predicted.eq(target).sum().item()

    train_loss_values.append(train_loss / len(loaders['train']))
    train_accuracy_values.append(correct_train / total_train)

    model.eval()
    test_loss = 0
    correct_test = 0
    total_test = 0

    with torch.no_grad():
        for data, target in loaders['test']:
            data, target = data.to(device), target.to(device)
            output = model(data)
            loss = loss_fn(output, target)
            test_loss += loss.item()
            _, predicted = output.max(1)
            total_test += target.size(0)
            correct_test += predicted.eq(target).sum().item()

    test_loss_values.append(test_loss / len(loaders['test']))
    test_accuracy_values.append(correct_test / total_test)



epochs = range(1, 11)
plt.figure(figsize=(12, 4))


plt.subplot(1, 2, 1)
plt.plot(epochs, train_accuracy_values, label='Training Accuracy')
plt.plot(epochs, test_accuracy_values, label='Testing Accuracy')
plt.title('Accuracy per Epoch')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()


plt.subplot(1, 2, 2)
plt.plot(epochs, train_loss_values, label='Training Loss')
plt.plot(epochs, test_loss_values, label='Testing Loss')
plt.title('Loss per Epoch')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()


model.eval()
all_predictions = []
all_targets = []

with torch.no_grad():
    for data, target in loaders['test']:
        data, target = data.to(device), target.to(device)
        output = model(data)
        _, predicted = output.max(1)
        all_predictions.extend(predicted.cpu().numpy())
        all_targets.extend(target.cpu().numpy())


cm = confusion_matrix(all_targets, all_predictions)


classes = ['Class 1', 'Class 2', 'Class 3', 'Class 4']
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)
disp.plot(cmap='viridis', values_format='d')
plt.title('Confusion Matrix for the Test Set')
plt.show()

